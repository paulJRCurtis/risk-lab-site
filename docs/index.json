[{"uri":"http://paulJRCurtis.github.io/risk-lab-site/patching-controls-with-ssm/1-current-os/","title":"Determine the current OS versions","tags":["AWS Systems Manager","Detective Controls"],"description":"","content":"In this step we will use AWS Systems Manager - Inventory to determine the operating systems versions how many instances are running each operating systems.\n1. Go to AWS Systems Manager - Inventory Select Systems Manager from the AWS Console.\nIn the navigation pane, choose Inventory.\nIf you can only see the AWS Systems Manager home page, you may need to click on the menu icon (☰) in the top left to open the navigation pane, and then choose Inventory.\nYou will see something similar to the below.\n2. Ensure Inventory is enabled You may see that not all of the instances in the environment have inventory enabled.\nIf this is the case enable the inventory and wait for this process to complete. You may need to wait for a few minutes while the inventory is completed. Reload the page after a few minutes to check progress.\nIf you scroll down the inventory page you will see summaries of the operating system versions and other software running on the instances.\n"},{"uri":"http://paulJRCurtis.github.io/risk-lab-site/1-start-workshop/","title":"Start the Workshop","tags":[],"description":"","content":"To start the workshop, follow one of the following depending on whether you are;\nrunning the workshop on your own (in your own account),\nor\nattending an AWS hosted event (using AWS provided hashes)\n"},{"uri":"http://paulJRCurtis.github.io/risk-lab-site/patching-controls-with-ssm/2-set-patch-baselines/","title":"Set patch baselines","tags":["AWS Systems Manager","Detective Controls"],"description":"","content":"As well as providing insight into the environment systems manager allows you to actively manage instances including applying patches. Patch Manager has predefined patch baselines for each operating system it supports. You can use these patch baselines to patch your instances, or you can create your own. In this Jam we will use the predefined patch baselines.\nThe environment provided for this challenge includes two fleets of EC2 Instances, one fleet includes three Amazon Linux 2 instances, the other two instances running a version of Windows. An EC2 Fleet is a way of grouping and managing EC2 instances and provisioning using the lowest price combination of instances available. You can learn more about Fleets on the Introducing Amazon EC2 Fleet page.\nThe EC2 instances in the two fleets provided have been grouped so they can receive their their respective patched. These groups are unsurprisingly called \u0026lsquo;Patching Groups\u0026rsquo;. The two patch groups that have been created for you are: jam-linux-app-patch-group and jam-windows-app-patch-group.\nRemember the following terms;\n Patch baseline - the patches that are to be applied to an operating system to keep it up to date. Patch group - the set of instances that patched will be applied to.  Your task is to tell Patch Manager which patch baseline to use for your two patching groups. The patch baselines we will use are the default baselines for the Amazon Linux 2 and Windows operating systems (note the difference between Linux and Linux 2). We will modify patch groups to be associated with the patch groups jam-linux-app-patch-group and jam-windows-app-patch-group.\n1. Open Patch Manager - Patch Baselines To set a patch baseline open the AWS Systems Manager console and in the navigation pane, choose Patch Manager.\nIf the AWS Patch Manager home page opens first, click View predefined patch baselines, this lists AWS managed patching baselines.\nOtherwise you will be taken directly to the Patch baselines screen. This screen lists the patch baselines for each of the supported operating systems. For some operating systems you may more than one entry - but there will only be one marked as default.\nSelect the default patch baseline for Windows - make sure it is the Default, and then under Actions select Modify patch groups\nFrom here add the Patch group jam-windows-app-patch-group.\nYou will need to repeat this process for the jam-linux-app-patch-group - Amazon Linux 2.\n"},{"uri":"http://paulJRCurtis.github.io/risk-lab-site/patching-controls-with-ssm/3-review-compliance/","title":"Review compliance","tags":["AWS Systems Manager","Detective Controls"],"description":"","content":"Now that you have set the patching baseline for your two patch groups (jam-windows-app-patch-group and jam-linux-app-patch-group) you have something to compare against. You now need to determine the effectiveness of the current manual patching controls. To do this you will identify the number of non-compliant resources.\n1. Run Patch Manager Scan From Patch Manager select Patch Now\nClick Patch now\n2. Scan Instances Run Patch Manager to Scan only.\nYou will see the progress tracked on screen, wait for a couple on minutes for the scan to complete.\n2. Review Compliance Use AWS Systems Manager - Compliance to view the compliant and non-compliant resource.\nGo to the Compliance screen in Systems Manager, you will see a screen similar to the below. However the number of compliant and non-compliant instances my vary.\n"},{"uri":"http://paulJRCurtis.github.io/risk-lab-site/patching-controls-with-ssm/4-maintenance-window/","title":"Create a Maintenance Window","tags":["AWS Systems Manager","Detective Controls"],"description":"","content":"AWS Systems Manager Maintenance Windows let you define a schedule for when to perform potentially disruptive actions on your instances such as patching an operating system, updating drivers, or installing software or patches. These may require Systems Manager to perform a restart so these actions should be scheduled appropriately.\nCreate a maintenance window which you will use to patch the Windows and Amazon Linux 2 instances. The details of the maintenance window details such as time, duration, frequency are all up to you.\nTo create a maintenance window goto Maintenance Windows on the Systems Manager navigation pane.\nYou can then set the Name and Description of your maintenance window to whatever you like, noting the valid characters.\nTo set the Schedule uss the Cron schedule builder, but you can set schedule details as you wish.\nOnce you satisfied with your maintenance window click Save changes\n"},{"uri":"http://paulJRCurtis.github.io/risk-lab-site/tags/artifact/","title":"AWS Artifact","tags":[],"description":"&lt;p&gt;AWS Artifact is your go-to, central resource for compliance-related information that matters to you. It provides on-demand access to AWS’ security and compliance reports and select online agreements.&lt;/p&gt;&lt;p&gt;To find out more go to &lt;a href=&#39;https://aws.amazon.com/artifact/&#39; target=&#39;_blank&#39;&gt;AWS Artifact&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;You can access AWS Artifact directly from the &lt;a href=&#39;https://console.aws.amazon.com/artifact&#39; target=&#39;_blank&#39;&gt;AWS Management Console&lt;/a&gt;.&lt;/p&gt;","content":""},{"uri":"http://paulJRCurtis.github.io/risk-lab-site/tags/beginner/","title":"Beginner","tags":[],"description":"blah blah","content":""},{"uri":"http://paulJRCurtis.github.io/risk-lab-site/2-know-the-console/","title":"Getting to Know the Console","tags":[],"description":"","content":"Login to your AWS Account If you haven\u0026rsquo;t already, logon to your AWS account. If you don\u0026rsquo;t have an account, go to Start Workshop.\nLet\u0026rsquo;s get to know the Management Console\nThe AWS Management Console is a web application that comprises and refers to a broad collection of service consoles for managing Amazon Web Services. When you first sign in, you see the console home page.\nAlong the top menubar you will see a few important elements we will use often.\nAWS Logo Clicking on the AWS logo will bring you back to this console screen.\nServices Dropdown Choose Services to open a full list of services. On the upper right of the page, choose Group to see the services listed by category or choose A–Z to see an alphabetical listing. Then choose the service that you want. Clicking Services again will close the list.\nAlert Clicking on alerts will display a dropdown showing Open issues, scheduled changes and Other notifications, as well as the option to show all alerts.\nClicking any of these will take you to the Personal Health Dashboard. Personal Health Dashboard gives you a personalized view into the performance and availability of the AWS services underlying your AWS resources, to learn more go to AWS Personal Health Dashboard.\nUser/Account Dropdown The User/Account Dropdown is on which we will use on occasionally during the labs. Lets step through the information on the dropdown. User - the image below shows the Federated Login that you will see if your identity is provided to the AWS Console form an external identity provider - in the example show this is the AWS Event Engine. If you signed on directly to the console you will see IAM User Account: this is the account Id, the example shows a number but you can also setup and account alias which is easier to remember. The next grouping of options may vary slightly depending on your access but they deal with billing and your credentials. The final option is to Sign Out. Region Dropdown For many services, you can choose a Region that specifies where your resources are hosted. You do not choose a Region for the AWS Management Console or for some services, such as IAM. To choose a Region\n In the AWS Management Console, choose a service to go to that service\u0026rsquo;s console. On the navigation bar, choose the name of the currently displayed Region. When you choose a Region, that Region becomes the default in the console.  Your will only be able to complete this workshop in the Sydney (ap-southeast-2) Region.\n Support Dropdown This dropdown lists the various support options and resources available to you.\n"},{"uri":"http://paulJRCurtis.github.io/risk-lab-site/1-start-workshop/on-your-own/create-an-aws-account/","title":"Create an AWS Account","tags":[],"description":"","content":" Your account must have the ability to create new IAM roles and scope other IAM permissions.\n   If you don\u0026rsquo;t already have an AWS account with Administrator access: create one now by clicking here\n  Once you have an AWS account, ensure you are following the remaining workshop steps as an IAM user with administrator access to the AWS account: Create a new IAM user to use for the workshop\n  Enter the user details:   Attach the AdministratorAccess IAM Policy:   Click to create the new user:   Take note of the login URL and save:   "},{"uri":"http://paulJRCurtis.github.io/risk-lab-site/1-start-workshop/at-an-aws-event/aws-workshop-portal/","title":"AWS Workshop Portal","tags":[],"description":"","content":"Login to AWS Workshop Portal This workshop creates an AWS account. You will need the Participant Hash provided upon entry, and your email address to track your unique session.\nUse Chrome or Firefox to ensure a good experience.\n 1. Go to Event Engine Connect to the portal by clicking the button or browsing to https://dashboard.eventengine.run. The following screen will be displayed.\n2. Enter Hash Code Enter the provided hash in the text box. The button on the bottom right corner changes to Accept Terms \u0026amp; Login. Click on that button to continue.\n3. Open AWS Console Click on AWS Console on dashboard.\nTake the defaults and click on Open AWS Console. This will open AWS Console in a new browser tab. You will not need the Credentials / CLI Snippets for this workshop.\n"},{"uri":"http://paulJRCurtis.github.io/risk-lab-site/1-start-workshop/on-your-own/","title":"In your own account","tags":[],"description":"","content":" Only complete this section if you are running the workshop on your own. If you are at an AWS hosted event (such as an Immersion Day, etc), go to At an AWS Event\n Contents  Create an AWS Account   "},{"uri":"http://paulJRCurtis.github.io/risk-lab-site/4-detective-controls-config/","title":"Detective Controls with Config","tags":["AWS Config","Detective Controls"],"description":"","content":"In this workshop we will use three AWS Config and AWS Config Rules to demonstrate how to automate controls, in this case, the controls will check the configuration of an Amazon Simple Storage Service (Amazon S3) bucket. The same approach can be applied to many AWS services.\nAWS Config is a service that enables you to assess, audit, and evaluate the configurations of your AWS resources. Config continuously monitors and records your AWS resource configurations and allows you to automate the evaluation of recorded configurations against desired configurations.\nAt the time this workshop was being created there were 150 AWS Managed Config Rules to choose from, and the number is growing.\nWith Config, you can review changes in configurations and relationships between AWS resources, dive into detailed resource configuration histories, and determine your overall compliance against the configurations specified in your internal guidelines. This enables you to simplify compliance auditing, security analysis, change management, and operational troubleshooting.\nTake a minute (1:34) to watch the video below.\n  "},{"uri":"http://paulJRCurtis.github.io/risk-lab-site/patching-controls-with-ssm/5-patch-manager-config/","title":"Create Patch Manager configuration","tags":[],"description":"","content":"Now that you have setup the patch baselines and the maintenance window there is one final task to configure Patch Manager to automatically apply patches as per your schedule.\nConfigure Patch Manager to apply patched to both of your patch groups during the maintenance window you set up in the previous task.\nFrom the Patch Manager console select Configure patching\nComplete the Patch manager configuration by selecting the two patch groups, the maintenance schedule you created earlier, and selecting Scan and install, then click Configure patching.\n"},{"uri":"http://paulJRCurtis.github.io/risk-lab-site/patching-controls-with-ssm/6-patch-now/","title":"Patch Now","tags":[],"description":"","content":"Your final step is to patch the instances in your environment now so you can see the results in the Compliance\nFrom the Patch Manager console select Configure patching\nClick Patch now\nUpdate the options as per below, including Scan and Install and Reboot if needed.\nClick Patch now\nThe patch progress screen will be displayed.\nIt may take awhile to update as Patch Manager applies all the required operating system and agent updates. This screen will automatically update as the patching operation progresses.\nCongratulations! You have successfully completed this workshop.\n "},{"uri":"http://paulJRCurtis.github.io/risk-lab-site/patching-controls-with-ssm/","title":"Patching Controls with Systems Manager","tags":["AWS Systems Manager","Detective Controls"],"description":"","content":"Many organizations struggle to keep up with patching requirements. Sometimes one of the challenges is to get a definitive inventory of the operating systems and software running in the environment.\nIn this workshop we will explore using AWS Systems Manager to gain visibility of the environment and to automate patching controls.\nIn a cloud environment there are two different approaches to patching based on whether the architecture includes instances that are immutable or non-immutable. This might seem a confusing statement, but lets break it down. First, instances are the equivalent of servers in cloud speak. An immutable instance is one that is never changed or updated, it just gets replaced. When an patch exists for an immutable instance the image, or Amazon Machine Image (AMI), used to create the instance is update. The instances can be then be replaced with instance created from the new AMI.\nImmutable infrastructure has some big benefits including greater infrastructure consistency, a more predictable deployment process, and the ability to easily scaled up and down to meet capacity requirements.\nThis immutable approach cannot be applied to every instance as some applications don\u0026rsquo;t allow for it. You need to identify these non-immutable instances that do not meet patch baselines. AWS Systems Manager - Patch Manager provides the capability to do this, not only for AWS instances but for your on-premises instances too.\nFor more information see our resources on Automated patching for non-immutable instances in the hybrid cloud using AWS Systems Manager\nIn this workshop you will get a clear view of the operating systems and software running in the environment, identify patching requirements, and set up a corrective controls which will patch the selected instances.\n"},{"uri":"http://paulJRCurtis.github.io/risk-lab-site/1-start-workshop/at-an-aws-event/","title":"At an AWS Event","tags":[],"description":"","content":" Only complete this section if you are at an AWS hosted event (such as an Immersion Day, or any other event hosted by an AWS employee). If you are running the workshop on your own, go to: On your own.\n Contents  AWS Workshop Portal   "},{"uri":"http://paulJRCurtis.github.io/risk-lab-site/","title":"Risk &amp; Compliance Labs","tags":[],"description":"","content":"Risk \u0026amp; Compliance Labs Introduction These labs have been developed specifically with risk, compliance and controls assurance stakeholders in mind. AWS provides a wealth of services and tools to assist in effective management and governance and provides an unprecedented level of transparency. These labs aim to demonstrate how these services and the telemetry available on the platform can be used to automate controls assurance and provide a real time risk data. These labs have been designed to cater for the absolute beginner, building up to more advanced topics.\nThis repository contains documentation and code in the format of hands-on labs to help you learn, measure, and build. Some labs, particularly the introductory labs maybe be simplified to demonstrate concepts rather than attempting to be production ready approaches. Where this is the case it will be noted in the lab.\nThe labs are categorized into Beginner, Intermediate and Advanced.\nPrerequisites An AWS account that you are able to use for learning and experimenting, that is not used for production or other purposes. If you are doing these labs at an AWS event you may be given an account.\nBeginner Labs For Beginner labs there are no prerequisites and no assumed AWS knowledge, however the labs to build on each other and should ideally be taken in sequence.\nIntermediate Labs For Intermediate and Advanced Labs you may require the following.\n A working directory where you have the rights to create files and directories. A text editor, we will be editing a few configuration files and scripts but not doing any major coding so a basic editor will do - notepad or TextEdit are fine. We will be using zip files so you will need to be able to un-zip and zip files.  "},{"uri":"http://paulJRCurtis.github.io/risk-lab-site/4-detective-controls-config/1-config-setup/","title":"Enable AWS Config","tags":[],"description":"","content":"First, we need to enable AWS Config and begin tracking of your resources.\n1. Login to your AWS Account If you haven\u0026rsquo;t already logon to your AWS account, do so now. If you don\u0026rsquo;t yet have an account go to Start the Workshop\n2. Access the AWS Config Console Select the Services dropdown on the menu bar at the top left. Select Config under Management \u0026amp; Governance, or search for Config using Find Services.\nIf this is your first time using AWS Config\nSelect Get started from the AWS Config intro screen.\nIf you’ve already used AWS Config\nYou will start at the AWS Config Dashboard, select Settings on the menu to the left.\n3. Select resource types to record On the Settings page, under Resource types to record, ensure Record all resources supported in this region checkbox is selected and you may also check the checkbox for Include global resources, but it\u0026rsquo;s not required for this workshop. Checking these two boxes means that AWS Config will record configuration changes for all supported resources all resources as well as configuration changes for AWS Identity and Access Management (IAM) resources which are global resources. Global resources are not tied to an individual region and can be used in all regions.\n4. Create Amazon S3 bucket for configuration history AWS Config needs a place to store configuration history and configuration snapshot files, we will use Amazon Simple Storage Service (Amazon S3) to provide this storage space - what AWS calls an S3 Bucket.\nUnder Amazon S3 bucket, select Create a bucket to have the Amazon S3 bucket created automatically.\nThis S3 bucket will be used to store the history used by Config, but to keep things simple and remove the need to create a second Bucket, we will be applying the Config Rules to this same S3 Bucket.\n 5. AWS Config role There is no need to change any settings in this section, Create AWS Config service-linked role should already be selected.\nIt is worth taking a moment to understand that for AWS Config to access other services like S3 and SNS we need to grant it permissions. This step crates a role for Config that will allow Config to access the S3 bucket and the SNS topic we set-up in the steps above.\n Click Next.\n"},{"uri":"http://paulJRCurtis.github.io/risk-lab-site/4-detective-controls-config/2-select-rules/","title":"Select AWS Config Rules","tags":[],"description":"","content":"1. Select Config Rules In this introductory workshop we will use three of the AWS Managed Config Rules that relate to S3.\nThe rules we will use are;\n s3-bucket-server-side-encryption-enabled s3-bucket-public-write-prohibited s3-bucket-public-read-prohibited  The easiest way to find these rules is to enter s3-bucket into the filter field.\nSelect the three rules listed above and click Next\n2. Review Config Rules Click Confirm\n"},{"uri":"http://paulJRCurtis.github.io/risk-lab-site/4-detective-controls-config/3-dashboard/","title":"Review Dashboard","tags":[],"description":"","content":"Return to the Config Console.\n1. Explore the Dashboard Take a few minutes to explore the information on the Dashboard.\nOn the right, in the Compliance status window you can see that there are a total of 3 rules - 1 Noncompliant and 2 Compliant, you can also see that there are 2 resource which are noncompliant.\nThe Noncompliant rules by noncompliant resource count lists noncompliant rules listed by the number of non-compliant resources. In this case there is only one noncompliant rule and two noncompliant resources.\nTo the left is the Resource Inventory, this lists the resources in the account. the number you see may differ from the image shown, it al depends upon what is deployed into the account.\n2. Review noncompliant rule(s) In the Noncompliant rules window select S3-bucket-server-side-encryption-enabled. This will take you to a screen displaying the rule details and the Resources in scope.\nYou will see that we have created some example S3 buckets for business units of AnyCompany.\n3. Drill into noncompliant resources Click on one of the bucket names to display the details of the noncompliant bucket. "},{"uri":"http://paulJRCurtis.github.io/risk-lab-site/4-detective-controls-config/4-rule-scope/","title":"Rule Scope","tags":[],"description":"","content":"Controls should be considered from both a design and operating effectiveness perspective. As you think about your assurance program you will want to consider the frequency and breath of your assurance. With AWS Config rules you can control the frequency and scope of application of the rule.\nFrequency of Operation AWS Config compares your resources to the conditions of the rule. After this initial evaluation, AWS Config continues to run evaluations each time one is triggered. The evaluation triggers are defined as part of the rule, and they can include one or both of the following types:\n Configuration changes – AWS Config triggers the evaluation when any resource that matches the rule\u0026rsquo;s scope changes in configuration. The evaluation runs after AWS Config sends a configuration item change notification. Periodic – AWS Config runs evaluations for the rule at a frequency that you choose (for example, every 24 hours).  Scope of Application The rules can be applied based on;\n Type of resources - When any resource that matches the specified type, or the type plus identifier, is created, changed, or deleted - in this case we applied the rules to all S3 buckets in the account. Tags - When any resource with the specified tag is created, changed, or deleted. A tag is a simple label consisting of a customer-defined key and an optional value that can make it easier to manage, search for, and filter resources. Tags are an important part of effective operations and governance and can be used in many ways including for the classification of data. The Tagging Best Practice Whitepaper is a great resource to find out more. All changes - When any resource recorded by AWS Config is created, changed, or deleted.  To review these settings go to the Rules page by selecting Rules on the menu bar to the left and click on the s3-bucket-public-write-prohibited rule name. This will take you to the rules page.\nNote the Trigger type will show if the rule is triggered by configuration changes and the frequency if it is periodic. The resource types shows the scope of application as discussed above - in this case the rule applies to all S3 Buckets in the account.\n "},{"uri":"http://paulJRCurtis.github.io/risk-lab-site/4-detective-controls-config/5-remediate/","title":"Remediate","tags":[],"description":"","content":"Now you can take this control from detective to an automated corrective control by adding automated remediation to the s3-bucket-server-side-encryption-enabled config rule you set-up.\nThis means that AWS Config will automatically apply server side encryption to any bucket in the account found that doesn\u0026rsquo;t have it turned on.\nIn a production environment you want to carefully choose the actions you automate and the resources that these actions apply to, but automation is a powerful way to move to a more proactive risk and controls management stance.\n1. Find the AutomationAssumeRole To turn on the auto remediation action you will need to provide some parameters, one of these is the;\n AutoAssumeRole This is the role (and associated permissions) that allows the auto remediation to happen. We will ue the AutoAssumeRole ARN or Amazon Resource Name. The ARN is used to uniquely identify the role.  To find the AutomationAssumeRole you need to go to Roles in AWS Identity and Access Management (IAM).\nUse the Services dropdown to navigate the IAM and select Roles. From this screen you will see a list of existing roles and up the top you should see AutomationServiceRole.\nClick on the name of the role to see a summary of the role. At the top of this screen you will see Role ARN. Copy the ARN (you can do so easily by clicking the copy icon to the right). This is the string you will need to paste into the AutomatedAssumeRole back in Config.\nWhile you\u0026rsquo;re here, you can see that the permissions of this role are defined by the policy \u0026ldquo;ConfigAutoRemediationPolicy\u0026rdquo;. Which makes sense given what we are tying to do. If you have time you gan dig in a bit deeper to see the exact permissions this policy grants.\n2. Select the s3-bucket-server-side-encryption-enabled rule Now that you have the ARN it\u0026rsquo;s time to head back to AWS Config. From the AWS Config Console select Rules on the navigation menu on the left.\nFrom here you will see the three rules you implemented, and that the Remediation action for each is \u0026ldquo;Not set\u0026rdquo;. Click on s3-bucket-server-side-encryption-enabled.\n3. Configure Auto remediation From the rules page, click on the Edit or Actions button at the top right.\nComplete the remediation section of the form as per below.\nRemediation Action must be set to AWS-EnablesS3BucketEncryption.\nIf you see an Auto Remediation Yes / No selection - ensure Yes is selected.\nThe Resource ID Parameter must be set to BucketName. This tells Config that the Bucket Name will be variable.\nThe three main parameters are;\n AutoAssumeRole This is the role (and associated permissions) that you copies in step 1. This allows the auto remediation to happen, an Amazon Resource Name (ARN) is used to uniquely identify the role. BucketName The name of the bucket to apply the auto remediation to. You will should see this is greyed out because you selected BucketName as the Resource ID Parameter. You do not want to specify a particular bucket because we want the remediation to be applied to all buckets. SSEAlgorthum The encryption algorithm, this must be set to AES256.  Click Save changes\nYou will then be taken back to the Rules page where you will see the Remediation action has been set but the Rule is still showing noncompliant resource(s). It will take around 5-10 minutes for the remediation actions to run and for the config status to be refreshed. Move on to the next step and we\u0026rsquo;ll come back and check later.\n"},{"uri":"http://paulJRCurtis.github.io/risk-lab-site/4-detective-controls-config/6-timelines/","title":"Explore Timelines","tags":[],"description":"","content":"1. Return to Config Select Resources in the navigation pane and type \u0026ldquo;Bucket\u0026rdquo; in to the Resource type drop down - make sure you select the tick-box and Click Look up. 2. Select a bucket Click on the bucket name that starts with \u0026ldquo;config-bucket\u0026rdquo;\n2. Access Resource timelines From the Resource screen click the Configuration Timeline in the top right. 3. Review Resource configuration timeline You should now see the Configuration timeline tab of the timeline page for the resource.\nOn this tab we can see two entries on the timeline. The first is the Resource discovery time and has two Events. Click on the Events hyperlink for this first entry on the timeline or scroll down the page.\nThis shows the S3 bucket creation link to AWS CloudTrail. CloudTrail provides event history of your AWS account activity, including actions taken through the AWS Management Console, AWS SDKs, command line tools, and other AWS services.\nReturn now to the timeline a select the second entry on the timeline @ 5:17:37 PM and scroll down the page. You can see that this entry on the timeline logs the application of encryption we did during the remediation step.\n4. Review Resource configuration timeline Select the Compliance timeline tab and take a few minutes to explore the compliance timeline. This timeline logs the same events and changes but provides a compliance view of the resource. You should now see that the auto remediation that you setup has run and that the bucket is compliant.\nYou have successfully completed this workshop, and if you have time you can move on to the next one.\n "},{"uri":"http://paulJRCurtis.github.io/risk-lab-site/tags/aws-config/","title":"AWS Config","tags":[],"description":"","content":""},{"uri":"http://paulJRCurtis.github.io/risk-lab-site/tags/aws-systems-manager/","title":"AWS Systems Manager","tags":[],"description":"","content":""},{"uri":"http://paulJRCurtis.github.io/risk-lab-site/categories/beginner/","title":"Beginner","tags":[],"description":"","content":""},{"uri":"http://paulJRCurtis.github.io/risk-lab-site/categories/","title":"Categories","tags":[],"description":"","content":""},{"uri":"http://paulJRCurtis.github.io/risk-lab-site/tags/detective-controls/","title":"Detective Controls","tags":[],"description":"","content":""},{"uri":"http://paulJRCurtis.github.io/risk-lab-site/tags/","title":"Tags","tags":[],"description":"","content":""}]